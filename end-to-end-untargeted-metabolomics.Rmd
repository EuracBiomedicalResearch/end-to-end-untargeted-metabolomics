---
title: "End-to-end workflow for LC-MS/MS analysis using *RforMassSpectrometry* and *XCMS*"
author:
  - name: "Philippine Louail"
affiliation: "Eurac Research, Bolzano, Italy"
output: html_document
date: "2023-09-07"
---

```{r style, message = FALSE, echo = FALSE, warning = FALSE, results = "asis"}
library("BiocStyle")
library("knitr")
library("rmarkdown")
opts_chunk$set(message = FALSE, error = FALSE, warning = FALSE,
               cache = FALSE)
```

# Abstract

Metabolomics provides a real-time view of the metabolic state of examined
samples, with mass spectrometry serving as a key tool in deciphering intricate
differences in metabolomes due to specific factors. In the context of
metabolomic investigations, untargeted LC-MS/MS emerges as a powerful approach.
This paper focuses on a dataset aimed at identifying variations in plasma
metabolite levels between patients with Arrhythmogenic Cardiomyopathy (ACM) and
healthy controls.

Despite the potential insights offered by untargeted MS/MS data, a significant
challenge in the field lies in the absence of an efficient and scalable
infrastructure for its analysis. While various specialized packages exist for
specific analysis steps, seamless integration remains elusive. Addressing this
gap, we present an innovative R pipeline that leverages *XCMS*, *Spectra* and
*MsExperiment* to encompass all aspects of pre-processing and downstream
analyses for LC-MS/TS datasets in a reproducible manner. Our pipeline seamlessly
integrates Bioconductor packages, offering adaptability to diverse study designs
and analysis requirements.


# Keyword
LC-MS/MS, pre-processing, normalization, feature identification, Bioconductor,...

# Introduction

- Relevancy of the technic
- Challenges (explaining the need for seamless integragration and overall pipeline)
    existence of other pipeline or on other platform. how ours is better - or
    rather different: we provide a toolset to build customized workflows with
    possibility to integrate the full power of the R universe, compared to
    (rather limited) graphical user interface tools.
- Some note on reproducibility, such workflow enables reproducible analysis

Thus, we propose a highly-detailed and adaptable pipeline for LC-MS/MS data
analysis. Comprising pre-processing steps rooted in the *xcms* package, known
for its high adaptability to dataset-specific requirements. The detailed
normalization method is designed to eliminate as much unwanted variation as
possible.

Lastly, the identification of significant features will be demonstrated using
*MetaboAnnotation* in conjunction with *SIRIUS*.

# Data description

This dataset focuses on investigating the presence of metabolites with
significant differences in the plasma of individuals with Arrhythmogenic
Cardiomyopathy (ACM) compared to healthy controls (CTRL). The subset comprises
10 mzML files, with three samples each from ACM patients and healthy donors.
Additionally, four quality control (QC) samples, representing a pool of serum
samples from a large cohort, are included. The MS data is confined to a
retention time range of 20 to 230 seconds.

@jo: describe data - avoid ACM but use cardiovascular disease instead.

The data and metadata for this workflow are accessible on the massive database
under the ID: [ID].


# Workflow description

This pipeline here describes all steps required to preprocess and assign
features identity to LC-MS/MS data. It is performed thanks to the *MsExperiment*
and *PSpectra* packages that integrate multiple Bioconductor packages for
LC-MS/MS analysis. The pre-processing steps are performed using the *xcms*
packages and consist of Chromatogrphic peak detection, retention time alignment
and Correspondence.  The pre-processing of the data is then followed by
normalization, identification of features and lastly annotation of these
features. Laslty, *RColorBrewer*, *pander*, and *pheatmap* were used for data
visualization.

Our workflow is therefore based on the following dependencies:

```{r packages used, message=FALSE, warning=FALSE}
library(MsExperiment)
library(xcms)
library(Spectra)
library(RColorBrewer)
library(pander)
library(readxl)
library(MetaboCoreUtils)
library(pheatmap)
```

# Data import

The *mzML* files with the raw MS data are located within the *data/mzML* folder
of this repository. [ideally, they should be added and then downloaded from
MetaboLight].

```{r warning=FALSE}
#' read the sample descriptions from an xlsx sheet
pd <- read_xlsx("data/phenodata.xlsx") |>
    as.data.frame()

#' Import the data
#' Massive data bank extraction but for now not.
MZML_PATH <- "C:/Users/plouail/OneDrive - Scientific Network South Tyrol/end-to-end_worflow/data/mzML"

data <- readMsExperiment(paste0(MZML_PATH, "/", pd$mzML_file), sampleData = pd)
```

... just a tiny text with default everything is parallelized

```{r}
#' Set up parallel processing using 2 cores
if (.Platform$OS.type == "unix") {
    register(bpstart(MulticoreParam(2)))
} else {
    register(bpstart(SnowParam(2)))
}
```

# Data organisation

The experimental data is now a `MsExperiment` object:

```{r}
data
```

This `MsExperiment` object effectively manages the linkage between samples and
spectra, with its length defined by the number of samples within the object.
The phenodata, accessible through the `sampleData()` function, plays a crucial
role in LC-MS/MS analysis. Table 1 below build using the *pander* package
provides additional details about the samples in our dataset.

```{r phenodata, echo=FALSE}
sampleData(data)[, -5] |>
  as.data.frame() |>
  pandoc.table(style = "rmarkdown", caption = "Samples from the data set.")
```

There are `r length(sampleData(data))` samples in this data set. Below are
abbreviations essential for proper interpretation of the phenodata table:

- Injection Index: an index representing the order (position) in which
  individual samples were measured (injected) within the LC-MS measurement run.
- QC: Quality control sample
- CVD: Cardiovascular disease
- CTR: Control

```{r define-colors, include=FALSE}
#' Define colors for the different phenotypes
col_phenotype <- brewer.pal(8, name = "Dark2")[c(8, 4, 3)]
names(col_phenotype) <- c("QC",
                          "CVD",
                          "CTR")
col_sample <- col_phenotype[sampleData(data)$phenotype]
```

The MS data of this experiment is stored as a `Spectra` object within the
`MsExperiment` object and can be accessed using `spectra()` function.
Each element in this object is a spectrum - they are organised linearly and are
all combined in the same `Spectra` object one after the other (through retention
time and samples).

```{r}
#' Access Spectra Object
spectra(data)
```

```{r}
#' Check number of samples
length(data)
```

We therefore have an data set of `r length(data)` samples for a total of `r length(spectra(data))` spectra.
Below we also determine the retention time range for the entire data set.

```{r}
#' Retention time range for entire dataset
spectra(data) |>
rtime() |>
range()
```

Data obtained from LC-MS experiments are typically analyzed along the retention
time axis, while MS data is organized by spectrum, orthogonal to the retention
time axis. The `chromatogram()` function facilitates the extraction of
intensities along the retention time. However, access to chromatographic
information is currently not as efficient and seamless as it is for spectral
information. Work is underway to develop a `Chromatogram` object that is as
comprehensive and user-friendly as the existing `Spectra` object.

# Data visualization and general quality assessment

Effective visualization is paramount for inspecting and assessing the quality of
MS data. To generate a general overview of our LC-MS/MS data, we can:

- Combine all spectra measured into a single spectrum, termed the Base Peak
  Spectrum (BPS).
- Aggregate peak intensity for each spectrum, resulting in the Base Peak
  Chromatogram (BPC), which is orthogonal to the BPS.

## Visualisation of spectra data

The BPS collapses data in the retention time dimension, providing insights into
the most abundant mass-to-charge values (m/z) in the dataset, irrespective of
the retention time in which they were measured. Compared to the BPC, BPS
visualization is not as straightforward. Mass peaks, even if representing
signals from the same ion, will never be identical between consecutive spectra
due to slight differences influenced by the measurement error/resolution of the
instrument. After binning all mass spectra with an (m/z) bin size of 0.01 we
below aggregate all spectra per sample to a single base peak spectrum with the
`combineSpectra` function. The grouping algorithm from `combinePeaks`
iteratively combines peaks with differences in their m/z that are smaller than
`ppm`. The difference in m/z of individual peaks within a final peak group can
therefore be larger than `ppm`, especially for MS1 spectra or in general for
spectra with a very large number of peaks. Applying `combinePeaks` on binned
spectra data avoids this problem.

```{r bps, echo=TRUE, fig.width = 12, fig.height = 8, fig.cap = "Base peak spectra for the 10 samples of the experiment."}
#' binning and combining all spectra per file into a single spectrum
bps <- spectra(data) |>
    bin(binSize = 0.01) |>
    combineSpectra(f = fromFile(data), intensityFun = max, ppm = 5)

#' Plot the base peak spectra
par(mar = c(2, 1, 1, 1))
plotSpectra(bps)
```

The Base Peak Spectra (BPS) reveal the most prevalent ions present in each of
the samples. Here, there is observable overlap in ion content between the files,
particularly around 300 m/z and 700 m/z. However, distinct signals are also
apparent, indicating unique features in individual samples. In particular,
BPS for samples 1, 4, 7 and 10 (representing the QC samples) seem different than
those of the other samples. These differences might be explained by the fact
that the QC samples are serum samples, while the study samples represent plasma
samples, from a different sample collection.

Another general overview of spectra data could also be to compare the overall
similarities between the spectra. For this we first combine spectra for each
sample but this time first binning the all spectra. This will allow for more
accurate comparison when generating a similarity matrix using `compareSpectra`.

```{r compare-spectra, echo=TRUE}
#' Calculate similarities between BPS
sim_matrix <- compareSpectra(bps)
pheatmap(sim_matrix)
```

... Here maybe show some similar spectra instead of the next part (better
*story* and show similar functionalities)... some note that the QC samples
(pool) look different than the study samples.

It is strongly recommended to delve deeper into the data by exploring it in more
detail. This can be accomplished by carefully assessing our data and extracting
spectra or regions of interest for further examination. Here we will now look at
a single spectrum from a specific sample.

```{r }
#' Accessing a single spectrum
exspec <- spectra(data[1])[100]
plotSpectra(exspec)
```

This particular spectrum exhibits a significant peak around 300 m/z. To delve
into more details about this specific spectrum, a wide range of functions can be
employed:

```{r}
#' checking its intensity
intensity(exspec)

#' checking its rtime
rtime(exspec)

#' Checking its m/z
mz(exspec)
```

Additionally, we can concentrate on a specific subset of the data within a
designated m/z range and subsequently examine all the spectra within
that range. Below we focus on the m/z range that contains signal discriminating
the study plasma samples from the serum QC samples and further subset that to a
specific retention time range.

```{r}
exspec <- data |>
    filterMz(c(300, 304)) |>
    filterRt(c(25, 35)) |>
    spectra()

plotSpectra(exspec[10:13])
```

Within the entire dataset, there were `r length(exspec)` spectra measured in
this one second (only 4 are displayed here). Upon plotting them, various mass
peaks become apparent, with a notable common peak observed at 241 m/z. This peak
could potentially represent the ion of Cystine. Further investigation into this
observation can be conducted later.

## Visualization of chromatographic data

For visualizing LC-MS data, a Base Peak Chromatogram (BPC) or Total Ion
Chromatogram (TIC) serves as a valuable tool to assess the performance of liquid
chromatography across various samples in an experiment. In our case, we extract
the BPC from our data to create such a plot. The BPC captures the maximum peak
signal from each spectrum in a data file and plots this information against the
retention time for that spectrum on the y-axis. The BPC can be extracted using
the `chromatogram` function.

By setting the parameter `aggregationFun = "max"`, we instruct the function to
report the maximum signal per spectrum. Conversely, when setting
`aggregationFun = "sum"`, it sums up all intensities of a spectrum, thereby
creating a Total Ion Chromatogram (TIC).

```{r bpc1}
#' First extract and plot bpc for full data
bpc <- chromatogram(data, aggregationFun = "max")
```

```{r Plot bpc before filtering, echo=FALSE}
plot(bpc, col = paste0(col_sample, 80), main = "BPC")
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

After about 240 seconds no signal seems to be measured. Thus, we below filter
the data removing that part and also the first 10 seconds.

```{r filter rt}
#' Filter the data based on retention time
data <- filterRt(data, c(10, 240))
bpc <- chromatogram(data, aggregationFun = "max")
```

```{r plot after filtering, echo=FALSE}
plot(bpc, col = paste0(col_sample, 80), main = "BPC after filtering")
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

Initially, we examined the entire Base Peak Chromatogram (BPC) and subsequently
filtered it based on specific retention times. This not only results in a
smaller file size but also facilitates a more straightforward interpretation of
the BPC.

The final plot illustrates the BPC for each sample, providing insights into the
retention times captured during our experiment. It reveals the points at which
compounds eluted from the LC column. In essence, a BPC condenses the
3-dimensional LC-MS data (m/z by retention time by intensity) into 2 dimensions
(retention time by intensity).

Below we plot a heatmap derived from the TIC, we also used binning as a memory
saver and to group the intensity to facilitate comparison between samples. 

```{r heatmap1}
#' Heatmap from total ion chromatogram
#' - Create the TIC
#' - Bin the intensity values within bins of 2 seconds.
tic <- chromatogram(data, aggregationFun = "sum") |>
  bin(binSize = 2)

ticmap <- do.call(cbind, lapply(tic, intensity)) |>
  cor()

rownames(ticmap) <- colnames(ticmap) <- sampleData(data)$sample_name
ann <- data.frame(phenotype = sampleData(data)[, "phenotype"])
rownames(ann) <- rownames(ticmap)

pheatmap(ticmap, annotation_col = ann,
         annotation_colors = list(phenotype = col_phenotype))
```

- QCs separating from study.
- Two study samples different then other study samples; these are the samples
  with different/high signal in the rt range from about 40 to 12 seconds.
... discuss this...

### Internal standard

Throughout the entire process, it is crucial to have reference points within the
dataset, such as well-known ions. Most experiment nowadays include internal
standards (IS), it was the case here, we advise to use them for visualization
throughout the entire analysis process. For this experiment, we had a list of 15
IS, we looked at all of them and decided on two to follow our analysis process.
Below, we generate Extracted Ion Chromatograms (EIC) for these "test ions".
(here also precise that people can use commonly present ions in serum.)

```{r EIC extract for internal standard1, eval=FALSE, include=FALSE}
#' get the list
intern_standard <- read.delim("internal_standards.txt")
intern_standard <- intern_standard[!is.na(intern_standard$POS), ]
rownames(intern_standard) <- intern_standard$abbreviation

#' Calculate m/z based on  mass
intern_standard$mz <- mapply(intern_standard$formula,
                             intern_standard$POS, FUN = mass2mz)

##' Extract the EICs
#' Expand the m/z range by 0.05 on both sides
intern_standard$mzmin <- intern_standard$mz - 0.05
intern_standard$mzmax <- intern_standard$mz + 0.05
intern_standard$rtmin <- intern_standard$RT - 10
intern_standard$rtmax <- intern_standard$RT + 10

#' jo: maybe plot all of them? or too much info?
#' phili: i would put it as supplementary 
eic_is <- chromatogram(
    data,
    rt = as.matrix(intern_standard[, c("rtmin", "rtmax")]),
    mz = as.matrix(intern_standard[, c("mzmin", "mzmax")]))

#' jo: maybe even add information to that?
fData(eic_is)$mz <- intern_standard$mz
fData(eic_is)$rt <- intern_standard$RT
fData(eic_is)$name <- intern_standard$name
fData(eic_is)$abbreviation <- intern_standard$abbreviation
rownames(eic_is) <- intern_standard$abbreviation

cpt <- paste("Internal standard list with respective m/z and expected", 
"retention time (s)")
fData(eic_is)[, c("mz", "rt")] |>
  as.data.frame() |>
  pandoc.table(style = "rmarkdown", caption = cpt)
```

After extracting and looking at each of the IS present in our data, we decided
to visualize cystine and Methionine

```{r}
#' Extract cystine and Methionine m/z for future use; 2 ways of doing it.
cystine_mz <- calculateMass("C6H12N2O4S2") |> 
  mass2mz("[M+H]+")
cystine_mz <- cystine_mz[1, 1]

met_mz <- intern_standard["methionine_13C_15N", "mz"]

#' Plot the two IS; 2 ways of doing it.
eic_cystine <- chromatogram(nafld,
                            rt = c(200, 235),
                            mz = cystine_mz + c(-0.01, 0.01))
eic_met <- eic_is["methionine_13C_15N", ]
```

Now we can `plot()` these EICs:

```{r plot EIC1, echo=FALSE}
#' plot both EIC
par(mfrow = c(1, 2))
plot(eic_cystine, main = fData(eic_cystine)$name,
     col = paste0(col_sample, 80))
grid()
abline(v = fData(eic_cystine)$rt, col = "red", lty = 3)

plot(eic_met, main = fData(eic_met)$name,
     col = paste0(col_sample, 80))
grid()
abline(v = fData(eic_met)$rt, col = "red", lty = 3)
legend("topright", col = col_phenotype, legend = names(col_phenotype), lty = 1)
```

We can see a clear concentration difference between QCs and study samples for 
the L-Cystine ion. Methionine on the other hand shows a nice signal but some of
noise and a bigger retention time shift between samples.

It's also important to remember that these are not the endogenous compounds,
below we compare the endogenous and artificially added cystine ions.

```{r}
#' extract endogenous D4-cystine mass and EIC and plot.
cysmass <- calculateMass("C6H12N2O4S2") #' not super sure about that
cys_endo <- mass2mz(cysmass)[,1]

#' Plot versus spiked
par(mfrow = c(1, 2))
chromatogram(data, mz = cys_endo + c(-0.01, 0.01),
             rt = unlist(fData(eic_cystine)[, c("rtmin", "rtmax")]),
             aggregationFun = "max") |>
    plot(col = paste0(col_sample, 80)) |>
    grid()

plot(eic_cystine, col = paste0(col_sample, 80))
grid()
legend("topright", col = col_phenotype, legend = names(col_phenotype), lty = 1)
```

...

# Data pre-processing

Pre-processing stands as the inaugural step in the analysis of untargeted LC-MS
or gas chromatography (GC)-MS data. The primary objective of pre-processing is
the quantification of signals from ions measured in a sample, addressing any
potential retention time drifts between samples, and ensuring alignment of
quantified signals across samples within an experiment.

## Chromatographic peak detection

The initial pre-processing step involves detecting the presence of peaks along
the retention time axis. To achieve this, we employ the `findChromPeaks` function
within *xcms.* This function supports various algorithms for peak detection, with
notable options including:

- `MatchedFilterParam`: Implements peak detection as described in the original
  xcms article (C. A. Smith et al. 2006).

- `CentWaveParam`: Utilizes continuous wavelet transformation (CWT)-based peak
  detection (Tautenhahn, Böttcher, and Neumann 2008).

- `MassifquantParam`: Employs a Kalman filter-based peak detection
  (Conley et al. 2014).

The preferred algorithm, in this case, is CentWaveParam, known for its
effectiveness in handling non-Gaussian shaped chromatographic peaks or peaks
with different retention time widths commonly encountered in HILIC
separation.

```{r Default centwave param test}
#' Use default Centwave parameter
param <- CentWaveParam()

#' Evaluate for Cystine
cystine_test <- findChromPeaks(eic_cystine, param = param)
chromPeaks(cystine_test)

#' Evaluate for Methionine
met_test <- findChromPeaks(eic_met, param = param)
chromPeaks(met_test)
```

We will go through the main ones that be easily be adapted to the user dataset.
While *CentWave* is a highly performant algorithm, it necessitates adaptation to
each dataset. This implies that the parameters should be fine-tuned based on the
user's data. The example above serves as a clear motivation for users to
familiarize themselves with the various parameters. We will discuss the main
parameters that can be easily adjusted to suit the user's dataset:

- `ppm`: Typically dependent on the precision of the instrument.

- `peakwidth`: Specifies the minimal and maximal expected width of the peaks in
the retention time dimension. Highly dependent on the LC-MS system that
generated the dataset.

- `integrate`: This parameter defines the integration method. Here, we primarily
use `integrate = 2` because it is more suitable for Gaussian-shaped data and is
considered more accurate by the developers.

- verbosething that need to be updated.

To determine `peakwidth`, we recommend that users refer to previous EICs and
estimate the range of peakwidth they observe in their dataset. Ideally,
examining multiple EICs should be the goal. For this dataset, the peakwidths
are observed to be around 2 and 10 seconds.

To determine the `ppm`, a deeper analysis of the dataset is needed. It is
clarified above that `ppm` depends on the instrument, but users should not
necessarily input the vendor-advertised ppm. Here's how to determine it as
accurately as possible:

The following steps involve generating a highly restricted MS area with a single
mass per spectrum, representing the Cystine ion. These peaks are then extracted,
and the absolute value between them is calculated and expressed in ppm.

```{r ppm parameter1 }
#' Restrict the data to signal from Cystine
cst <- data[1L] |>
  spectra() |>
  filterRt(rt = c(208, 218)) |>
  filterMzRange(mz = cystine_mz + c(-0.005, 0.005))

lengths(cst)

#' Calculate the difference in m/z values between scans
mz_diff <- cst |>
    mz() |>
    unlist() |>
    diff() |>
    abs()

#' Express it in ppm
range(mz_diff * 1e6 / mean(unlist(mz(cst))))
```

Therefore, choose a ppm value close to the maximum within this range.

Now, rerun the process with the adapted settings. Users should also bear in mind
that for the peak-finding function to function correctly in a specific area, the
retention time range needs to be sufficiently wide. If the function fails to
find a peak in an Extracted Ion Chromatogram (EIC), the initial troubleshooting
step should be to increase this range. Also, the signal-to-noise threshold
`snthresh` should in general be reduced for peak detection in EICs, because
within the small retention time range usually not enough signal is present to
properly estimate the background noise.

```{r}
#' Parameters adapted for chromatographic peak detection on EICs.
param <- CentWaveParam(peakwidth = c(1, 8), ppm = 15, integrate = 2,
                       snthresh = 2)

cystine_test <- findChromPeaks(eic_cystine, param = param)
chromPeaks(cystine_test)

met_test <- findChromPeaks(eic_met, param = param)
chromPeaks(met_test)
```

A chromatographic peak was thus detected in each sample.

```{r echo=FALSE}
#' Plot test chromatogram
par(mfrow = c(1, 2))
plot(cystine_test, main = fData(cystine_test)$name,
     col = paste0(col_sample, 80),
     peakBg = paste0(col_sample, 40)[chromPeaks(cystine_test)[, "column"]])
grid()

plot(met_test, main = fData(met_test)$name,
     col = paste0(col_sample, 80),
     peakBg = paste0(col_sample, 40)[chromPeaks(met_test)[, "column"]])
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

These EICs seems to indicate that our settings are suitable for this dataset.
We can proceed to apply this algorithm to the entire dataset, and then extract
the EICs for our two test ions to confirm that the process has been successful.

```{r run find chrompeak on entire dataset}
#' Using the same settings, but with default snthresh
param <- CentWaveParam(peakwidth = c(1, 8), ppm = 15, integrate = 2)

data <- findChromPeaks(data, param = param, chunkSize = 5)

#' Test if we find Cystine and Methionine again
#' Phili: I'm thinking of putting the eic_is object in a different variables so that as additional info we can plot the IS after each steps and compare 
eics_is_noprocess <- eic_is

eic_is <- chromatogram(data,
                       rt = as.matrix(intern_standard[, c("rtmin", "rtmax")]),
                       mz = as.matrix(intern_standard[, c("mzmin", "mzmax")]))
fData(eic_is) <- fData(eics_is_noprocess)
# like this ? or create an fData object kind of ? 

eic_cystine <- eic_is["cystine_13C_15N", ]

eic_met <- eic_is["methionine_13C_15N", ]
```

```{r plot new eics, echo=FALSE}
#' Plot
par(mfrow = c(1, 2))
plot(eic_cystine, main = "L-Cystine (13C6, 99%; 15N2, 99%)",
     col = paste0(col_sample, 80),
     peakBg = paste0(col_sample[chromPeaks(eic_cystine)[, "sample"]], 40))
grid()

plot(eic_met, main = "L-Methionine (13C5, 99%; 15N, 99%)",
     col = paste0(col_sample, 80),
     peakBg = paste0(col_sample[chromPeaks(eic_met)[, "sample"]], 40))
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

### Refine chromatographic peaks

The identification of chromatographic peaks using *centWave* can sometimes
result in artifacts, such as overlapping or split peaks. To address this issue,
the `refineChromPeaks` function is utilized, in conjunction with the
`MergeNeighboringPeaksParam.` This function is designed to merge peaks that may
have been artificially split in the previous step.

Here are a few examples of peak detection artifacts. These examples are
pre-selected to illustrate the necessity of the next step:

```{r echo=FALSE}
#' Extract m/z-rt regions for selected peaks
mz_rt <- cbind(rtmin = c(155.2120, 181.71800),
               rtmax = c(201.0710, 228.13500),
               mzmin = c(191.0288,  53.50964),
               mzmax = c(191.0527, 53.53183))

#' Extract the EICs
eics <- chromatogram(data[3], rt = mz_rt[, c("rtmin", "rtmax")],
                     mz = mz_rt[, c("mzmin", "mzmax")])
#' Plot the EICs
plot(eics)
```

To address these artifacts, we need to configure parameters for the
`refineChromPeaks` function:

- `expandRt =`: Expansion on each side of the peak in the retention time
  dimension.
- `minProp =`: Chromatographic peaks with a distance tail to head in the
  retention time dimension that is less than `2 * expandRt` and for which the
  intensity between them is higher than minProp of the lower (apex) intensity of
  the two peaks are merged.
- `expandMz =`: Expansion on each side of the peak in the m/z dimension.

`expandRt` is usually set to approximately half the size of the average range
set up for peak detection, in this case 2.5 seconds. Additionally, `expandMz` is
kept relatively small (here at 0.0015) to prevent the merging of isotopes. It's
important to note that `minProp` should not be set too low, and we advise
against going below the default value of 0.75 to avoid merging neighboring peaks
that should remain separate.

```{r test merging}
#' set up the parameter
param <- MergeNeighboringPeaksParam(expandRt = 2.5, expandMz = 0.01,
                                    minProp = 0.75)

#' Perform the peak refinement on the EICs
eics <- refineChromPeaks(eics, param = param)
plot(eics)
```

We can observe that the artificially split peaks have been appropriately merged.
Therefore, we can apply this process to our entire dataset once again.

```{r}
#' Apply on whole dataset
data <- refineChromPeaks(data, param = param, chunkSize = 5)
chromPeakData(data)$merged |>
                      table()
```

apply to internal standard object 

```{r}
eics_is_chrompeaks <- eic_is

eic_is <- chromatogram(data,
                       rt = as.matrix(intern_standard[, c("rtmin", "rtmax")]),
                       mz = as.matrix(intern_standard[, c("mzmin", "mzmax")]))
fData(eic_is) <- fData(eics_is_chrompeaks)
# like this ? or create an fData object kind of ? 

eic_cystine <- eic_is["cystine_13C_15N", ]

eic_met <- eic_is["methionine_13C_15N", ]
```


## Retention time alignment

We will select for QC samples and observe the BPC again:

```{r echo=FALSE}
#' Get QC samples
QC_samples <- grep("QC", sampleData(data)$phenotype)

#' extract BPC
bpc_raw <- data[QC_samples] |>
  chromatogram(aggregationFun = "max", chromPeaks = "none")

plot(bpc_raw, col = paste0(col_phenotype[bpc$phenotype], 80))
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

Here, we can observe slight drifts in the signals of the QC samples, which were
measured with the same setup on the same day. This occurrence is common and
highly dependent on the LC setup and protocol used during data acquisition. To
facilitate proper post-processing analysis and the identification of features,
it is essential to minimize these differences in retention times between
samples.

The function utilized here is `adjustRtime`, and similar to the previous peak
detection steps, multiple algorithms are supported:

- `PeakGroupsParam`: This method is based on the retention time of a set of
anchor peaks in different samples, representing signals from ions across the
entire dataset.

- `ObiwarpParam`: This method is based on correlation-optimized warping.
The `binSize =` parameter signifies that the function creates warping functions
in mz bins of the size desired by the user.

For this example, we will use the *PeakGroups* method. As explained, we first
need group chromatographic peaks across samples in an initial correspondence
analysis using e.g. the `PeakDensityParam` method. This correspondence step will
also be used later to define all the features of our dataset.

For the initial correspondence step, we use the `PeakDensityParam` function with
the following parameters (which don't need to be optimized yet):

- `sampleGroups =` Specify the sample group to which each sample belongs.

- `minFraction =` Set the proportion of samples in one group for which a
chromatographic peak is identified. If `minFraction = 1`, a chromatographic
peak needs to be present in 100% of the samples to be defined as a feature.

- `binSize =` Define the size of the overlapping slices in the m/z
  dimension. Values between 0.01 and 0.1 might be acceptable and depend on the
  precision of the MS instrument. This parameter defines the acceptable
  difference in m/z values for chromatographic peaks of the same ion in
  different samples.

- `bw =` Define the bandwidth.

In non-test datasets, we recommend choosing a `minFraction` between 0.5 and 0.8.
`binSize` is highly dependent on the machine and should be neither too big nor
too small. Testing different values and observing change in alignment can help
determine it.

`bw` will be better explained in the correspondence step but essentially it
defines the smoothness of the curve to determine a peak, the default for this
parameter (30) is not acceptable for short (UHP) LCs, so we would advise to
choose a much lower value. Either by trial or by visual confirmation as it will
be described in later. It is important to note that the user should not have
really strict and optimized parameter for this initial correspondence as the
alignment is not corrected.

```{r}
# Grouping the peaks
param <- PeakDensityParam(sampleGroups = sampleData(data)$phenotype == "QC",
                          minFraction = 0.9,
                          binSize = 0.01,
                          bw = 2)
data <- groupChromPeaks(data, param = param)
```

The next step enables us to determine anchor peaks for the retention alignment
process. Which we will then input into the alignment function `adjustRtime`. The
parameters for this function are:

-`minFraction =` This has the same definition as above, but here the peaks will
be evaluate on the overall dataset not by groups (phenotype) as in the previous
function.

-`span =` This input defines the degree of smoothing by the LOESS function. This
smoothing allows for regions along the retention time axis to be adjusted. `span`
is advised to be set up around 0.4 and 0.6 to avoid overfitting or
underfitting. Again, it is suggested to use these values and eventually adapt if
the results from the alignment step are not satisfactory.

- `subsetAdjust` and `subset` Allows for subset alignment. Here we base the
retention alignment on the QC samples, i.e., retention time shifts will be
estimated based on these repeatedly measured samples and the resulting
adjustment applied to the entire data. For data sets in which QC samples
(e.g. sample pools) are measured repeatedly, we strongly suggest to use this
method. Note also that for subset-based alignment the samples should be ordered
by injection index (i.e. in the order in which they were measured during the
measurement run).

```{r}
#' Define parameters of choice
subset <- which(sampleData(data)$phenotype == "QC")
param <- PeakGroupsParam(minFraction = 0.9, extraPeaks = 50, span = 0.5,
                         subsetAdjust = "average",
                         subset = subset)

#' Input in the function
data <- adjustRtime(data, param = param)

#' See result
plotAdjustedRtime(data, col = paste0(col_sample, 80))
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

Once the alignment has been performed, the user should evaluate the results
using the `plotAdjustedRtime` function. This function allows us to visualize
the difference between adjusted and raw retention time for each sample on the
y-axis along the adjusted retention time on the x-axis. Dot points represent the
position of each anchor peak along the retention time axis. For optimal
alignment, these anchor peaks should be scattered all over the retention time
dimension, and the adjustment should not be too extreme.

All samples from the present data set were measured within the same measurement
run, thus only small retention time shifts were present. Therefore, only little
adjustments needed to be performed (shifts of at maximum 1 second as can be seen
in the plot above).

We can also compare before and after alignment. To access data before the
process, the function `dropAdjustedRtime()` can be used:

```{r}
#' get  data before alignment
data_raw <- dropAdjustedRtime(data)
```

We can use this to compare the BPC before and after alignment:

```{r bpc before and after1, echo=FALSE}
#' Plot the BPC before and after alignment
par(mfrow = c(2,1), mar = c(2, 1, 1, 0.5))
chromatogram(data_raw, aggregationFun = "max", chromPeaks = "none") |>
    plot(main = "BPC before alignment", col = paste0(col_sample, 80))
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)

chromatogram(data, aggregationFun = "max", chromPeaks = "none") |>
    plot(main = "BPC after alignment",
         col = paste0(col_sample, 80))
grid()
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty = 1)
```

The biggest effect can be seen for the retention time range from 120 to 130
seconds. Apart from that retention time range, only little changes can be
observed.


apply to internal standard object 

```{r}
eics_is_refined <- eic_is

eic_is <- chromatogram(data,
                       rt = as.matrix(intern_standard[, c("rtmin", "rtmax")]),
                       mz = as.matrix(intern_standard[, c("mzmin", "mzmax")]))
fData(eic_is) <- fData(eics_is_refined)
# like this ? or create an fData object kind of ? 

eic_cystine <- eic_is["cystine_13C_15N", ]

eic_met <- eic_is["methionine_13C_15N", ]
```

Can also observe it in our ions of interest:

```{r specific ion before and after1, echo=FALSE}
#' Similar comparison but this time filtering to see cystine
par(mfrow = c(1, 2), mar = c(4, 4.5, 2, 1))

old_eic_cystine <- chromatogram(data_raw,
                                mz = cystine_mz + c(-0.05, 0.05),
                                rt = c(205, 214))
plot(old_eic_cystine, main = "Cystine before alignment",  peakType = "none",
     col = paste0(col_sample, 80))
grid()
abline(v = intern_standard["cystine_13C_15N", "RT"], col = "red", lty = 3)

plot(eic_cystine, "Cystine after alignment", peakType = "none",
     col = paste0(col_sample, 80))
grid()
abline(v = intern_standard["cystine_13C_15N", "RT"], col = "red", lty = 3)
```

Little difference

```{r echo=FALSE}
#' Same for Met
par(mfrow = c(1, 2), mar = c(4, 4.5, 2, 1))
old_eic_met <- chromatogram(data_raw, mz = met_mz + c(-0.05, 0.05),
                            rt =  c(155, 165))
plot(old_eic_met, main = "Methionine before alignment",
     peakType = "none", col = paste0(col_sample, 80))
grid()
abline(v = intern_standard["methionine_13C_15N", "RT"], col = "red", lty = 3)

plot(eic_met, main = "Methionine after alignment",
     peakType = "none", col = paste0(col_sample, 80))
grid()
abline(v = intern_standard["methionine_13C_15N", "RT"], col = "red", lty = 3)
```

...better...

## Correspondence

We briefly touched on the subject of correspondence before to determine anchor
peaks, but it is an actual step in the preprocessing of LCMS data. Its goal is
to identify chromatographic peaks that originate from the same types of ions,
which are then grouped and referred to as LC-MS features.
(A visual representation similar to Johannes's drawing would be informative to
illustrate what features are—consider creating one using BioRender.)

The function `groupChromPeaks` can take two groups of parameters:

- `NearestPeakParam`: Similar method to initial correspondence from mzMine, as
it groups the peaks based on proximity from different samples in the
m/z-retention time interface.

- `PeakDensityParanm`: This grouping is based on the density of chromatographic
peaks from different samples along the retention time dimension within slices of
small m/z ranges. Essentially, peaks that have a similar retention time will
result in a higher peak density at a specific retention time and are thus
grouped together.

Here, we will use the `PeakDensityParam` method that was employed for grouping
before retention time alignment steps. To emphasize again the importance of
adapting the function parameters to the user dataset, we will show you the
results of using the default parameters for correspondence.

```{r}
#' Default parameter for the grouping and apply them to the test ions BPC
param <- PeakDensityParam(sampleGroups = sampleData(data)$phenotype, bw = 30)

plotChromPeakDensity(
    eic_cystine, param = param,
    col = paste0(col_sample, "80"),
    peakCol = col_sample[chromPeaks(eic_cystine)[, "sample"]],
    peakBg = paste0(col_sample[chromPeaks(eic_cystine)[, "sample"]], 20),
    peakPch = 16)
plotChromPeakDensity(eic_met, param = param,
    col = paste0(col_sample, "80"),
    peakCol = col_sample[chromPeaks(eic_met)[, "sample"]],
    peakBg = paste0(col_sample[chromPeaks(eic_met)[, "sample"]], 20),
    peakPch = 16)
```

For this method, it's crucial to understand that grouping depends on the
smoothness of the density curve and can be configured with the parameter `bw`.
As seen above, the smoothness is too high to properly group our features. When
looking at the default parameters, we can observe that indeed, the `bw`
parameter is set to `bw = 30`. To accommodate the multiple peaks present in our
1-Methylhistidine Extracted Ion Chromatogram (EIC), we need to reduce this
parameter. Let's see what happens when it is lowered to `bw = 2`.

Note:

```{r}
#' Updating parameters
param <- PeakDensityParam(sampleGroups = sampleData(data)$phenotype,
                        minFraction = 0.75, binSize = 0.015, bw = 1.8)

plotChromPeakDensity(
    eic_cystine, param = param,
    col = paste0(col_sample, "80"),
    peakCol = col_sample[chromPeaks(eic_cystine)[, "sample"]],
    peakBg = paste0(col_sample[chromPeaks(eic_cystine)[, "sample"]], 20),
    peakPch = 16)
plotChromPeakDensity(eic_met, param = param,
    col = paste0(col_sample, "80"),
    peakCol = col_sample[chromPeaks(eic_met)[, "sample"]],
    peakBg = paste0(col_sample[chromPeaks(eic_met)[, "sample"]], 20),
    peakPch = 16)
```

Now...

```{r}
#' Now apply to whole data
data <- groupChromPeaks(data, param = param)
```

Test appropriate grouping by examining an area with ions that are isomers:
1-MethylMethionine and 3-MethylMethionine.

```{r}
#' Extract chromatogram with signal for isomers 1-Methylhistidine and
#' 3-Methylhistidine
chr_test <- chromatogram(data, mz = met_mz + c(-0.01, 0.01),
                         rt = c(0, 200),aggregationFun = "max")
plotChromPeakDensity(
    chr_test, simulate = FALSE,
    col = paste0(col_sample, "80"),
    peakCol = col_sample[chromPeaks(chr_test)[, "sample"]],
    peakBg = paste0(col_sample[chromPeaks(chr_test)[, "sample"]], 20),
    peakPch = 16)
```



Looks good

resulting object:

```{r}
#' Definition of the features
featureDefinitions(data) |>
  head()
```


```{r}
featureValues(data, method = "sum") |>
  head()
```

F00005 and F00006 contain missing values in some samples

## Gap filling

The previously observed missing values (*NA*) could be attributed to various
reasons. Even if they represent a genuinely missing value, indicating that a
feature is truly not present in this dataset subset, it could also be a result
of a failure in the preceding preprocessing steps to identify a peak. It is
crucial to be able to recover missing values of the latter category as much as
possible. Let's examine how prevalent missing values are in our present dataset:

```{r}
#' Number of missing values
sum(is.na(featureValues(data)))
```

We can observe a substantial number of *NA* values in our dataset.

Now, let's delve into the process of *gap-filling*. We'll walk through the
steps of rescuing some (pre-)selected peaks that are only detected in a subset
of samples.

```{r peaks found in a few QC not all, echo=FALSE}
#' Updated code.
ftidx <- which(is.na(rowSums(featureValues(data))))
fts <- rownames(featureDefinitions(data))[ftidx]

fchrs <- featureChromatograms(data, features = fts, expandRt = 4)
plot(fchrs[1:8]) # essentially, plot them and select examples; first two seem OK

farea <- featureArea(data, features = fts[1:2])

chromatogram(data[c(2, 3)],
             rt = farea[, c("rtmin", "rtmax")],
             mz = farea[, c("mzmin", "mzmax")]) |>
    plot(col = c("red", "blue"), lwd = 2)
```

.. Discuss example

Will will therefore use the function `fillChromPeaks`  and `ChromPeakAreaParam`
which configure this algorithm.

```{r}
data <- fillChromPeaks(data, param = ChromPeakAreaParam(), chunkSize = 5)

#' How many missing values after
sum(is.na(featureValues(data)))
```

With `fillChromPeaks` we could thus rescue signal for all but
`r sum(is.na(featureValues(data)))` features.

Let's look at our previously missing value again:

```{r echo=FALSE}
#' Extract EICs again and plot them
chromatogram(data[c(1, 3)],
             mz = farea[, c("mzmin", "mzmax")],
             rt = farea[, c("rtmin", "rtmax")]) |>
    plot(col = c("red", "blue"), lwd = 2)
```


To assess the effectiveness of the gap-filling method for rescuing signals, we
can also plot the average of features with at least one missing value against
the average filled-in signal. It is advisable to perform this analysis on
repeatedly measured samples; in this case, our QC/POOL samples will be used.

For this, we extract:

- The detected features value: Set `filled = FALSE` in the `featuresValues`
input.

- The filled-in signal: For this, we first extract both detected and filled-in
together, and then we will replace the detected values with `NA`.

Then, we calculate the row averages of both of these matrices and plot them
against each other.

```{r Detected vs filled signal1}

#' Get only detected signal in QC samples
vals_detect <- featureValues(data, filled = FALSE)[, QC_samples]

#' Get detected and filled-in signal
vals_filled <- featureValues(data)[, QC_samples]

#' Replace detected signal with NA
vals_filled[!is.na(vals_detect)] <- NA

#' Identify features with at least one filled peak
has_filled <- is.na(rowSums(vals_detect))

#' Calculate row averages
avg_detect <- rowMeans(vals_detect, na.rm = TRUE)
avg_filled <- rowMeans(vals_filled, na.rm = TRUE)

#' Restrict to features with at least one filled peak
avg_detect <- avg_detect[has_filled]
avg_filled <- avg_filled[has_filled]

#' plot the values against each other (in log2 scale)
plot(log2(avg_detect), log2(avg_filled),
     xlim = range(log2(c(avg_detect, avg_filled)), na.rm = TRUE),
     ylim = range(log2(c(avg_detect, avg_filled)), na.rm = TRUE),
     pch = 21, bg = "#00000020", col = "#00000080")
grid()
abline(0, 1)

```

... looks really nice.

Then calculate statistics on these values. below we fit a linear regression
line to the data and summarize its results

```{r}
#' fit a linear regression line to the data
l <- lm(log2(avg_filled) ~ log2(avg_detect))
summary(l)
```


## Pre-processing result

The final results of these steps are stored within the *XcmsExperiment* object.
This includes the identified chromatographic peaks, the alignment results, as
well as the correspondence results. In addition, to guarantee reproducibility,
this result object keeps track of all performed processing steps and contains
the individual parameter objects used in the various preprocessing steps. These
can be extracted with the `processHistory()` function:

```{r Process history}
#' Process history
processHistory(data)
```

These pre-processing steps result in a two-dimensional matrix with abundances of
the so-called LC-MS features in all samples. At this stage, the features are
only characterized by their m/z and retention time.

Now, let's extract the results of the pre-processing:

```{r}
#' Extract results as a SummarizedExperiment
library(SummarizedExperiment)

res <- quantify(data, method = "sum", filled = FALSE)

assays(res)$raw_filled <- featureValues(data, method = "sum",
                                        filled = TRUE )

assayNames(res)
```

...Describe results

this summarized experiment can be subsetted by row or column easily:

```{r}
#' Subset to the first 15 features
res[1:15, ]
```

The features values are stored as an *assay* within the object and can be
accessed using the `assay()` function:

```{r}
#' Get feature values
assay(res) |> head()
```

Can also save as a normal .RData object. This is especially good to implement also during preprocessing steps for parallelizing  processes.

```{r}
# Save Summarized experiment and data object
save(res, file = "SumExp.RData")
save(data, file = "data.RData")
list.files()
```

# Data normalization

After preprocessing, data normalization or scaling might needed to be applied to
remove any technical variances from the data. While simple approaches like
median scaling can be implemented with a few lines of R code, more advanced
normalization algorithms are available in packages such as Bioconductor's
*preprocessCore*.

Unwanted variation can arise from various sources and is highly dependent on the
experiment. Therefore, data normalization should be chosen carefully based on
experimental design, statistical aims, and the balance of accuracy and precision
achieved through the use of auxiliary information.

Sample preparation biases could be evaluated using internal standards, depending
however also when they were added to the sample mixes during sample
processing. Repeated measurements of QC samples (usually a pool of the study
samples) on the other hand allows to estimate and correct for LC-MS specific
biases.


## Packages

```{r packages used1}
library(CompMetaboTools) # might want to get rid of this one though.
library(MetaboAnnotation)
```


## Initial quality assessment

A principal component analysis (PCA) is a very helpful tool for an initial,
unsupervised, quality assessment. In order to apply a PCA to the measured
feature abundances, we need however to impute missing values. We assume that
most missing values (after the gap-filling step) represent signal which is below
detection limit. In such cases, missing values can be replaced with random
values from the uniform distribution sampling numbers from half of smallest
measured value to the smallest measured value for a specific feature. The
uniform distribution is defined with two parameters (minimum and maximum) and
all values between them have an equal probability of being selected.

Below we impute missing values with that approach and add the resulting data
matrix as a new *assay* to our result object.

```{r}
#' Load preprocessing results
load("SumExp.RData")
load("data.RData")

#' Impute missing values using uniform distribution
na.unidis <- function(z) {
    na <- is.na(z)
    if (any(na)) {
        min = min(z, na.rm = TRUE)
        z[na] <- runif(sum(na), min = min/2, max = min)
    }
    z
}

#' Create an assay with the filled and imputed value.
tmp <- apply(assay(res, "raw_filled"), MARGIN = 1, na.unidis)
assays(res)$raw_filled_imputed <- t(tmp)
```

### PCA unsupervised

Look for overall biases in batch, sample, injection index,...
- scale (center and scale) on columns (features after the t() call) to
remove dependency on absolute abundances.

```{r unsupervised checks1, include=TRUE, fig.width = 10, fig.height = 5}
vals <- assay(res, "raw_filled_imputed") |>
    log2() |>
    t() |>
    scale(center = TRUE, scale = TRUE)

pca_res <- prcomp(vals, scale = FALSE, center = FALSE)

par(mfrow = c(1, 2), mar = c(4.5, 4.5, 4.5, 1))
plot_pca(pca_res, pc_x = 1, pc_y = 2, pch = 21,
         col = col_sample, bg = paste0(col_sample, 80),
         labels = res$injection_index)
legend("topleft", inset = c(0, -0.24), col = col_phenotype,
       legend = names(col_phenotype), lty=1, lwd = 2, xpd = TRUE, ncol = 3,
       cex = 0.7, title = "Phenotype", title.cex = 0.8)
plot_pca(pca_res, pc_x = 3, pc_y = 4, pch = 21,
         col = col_sample, bg = paste0(col_sample, 80),
         labels = res$injection_index)
```

Describe PCA
- clear separation of study (plasma) from QC Pool (serum) on PC1.
- separation based on phenotype on PC3.
- no relationship of PC1 to PC4 on injection index.

Precise that in some case instead of imputed it can be interesting to remove the
NA values and evaluate the PCA again.

### Intensity evaluation

Counts of non missing values and feature abundance distribution

```{r counts1, fig.height=7, fig.width=5, include=TRUE}
layout(mat = matrix(1:3, ncol = 1), height = c(0.2, 0.2, 0.8))

par(mar = c(0.2, 4.5, 0.2, 3))
barplot(apply(assay(res, "raw"), MARGIN = 2, function(x) sum(!is.na(x))),
        col = col_sample, ylab = "features raw data", xaxt = "n", space = 0.012)
barplot(apply(assay(res, "raw_filled"), MARGIN = 2, function(x) sum(!is.na(x))),
        col = col_sample, ylab = "features filled data", xaxt = "n", space = 0.012)
boxplot(log2(assay(res, "raw_filled")), xaxt = "n",
        ylab = expression(log[2]~abundance~filled~data),
        col = col_sample, outline=FALSE, medlty = "blank", border = col_sample,
        boxwex = 0.99 )
points(colMedians(log2(assay(res, "raw_filled")), na.rm = TRUE), type = "b",
       pch = 16) # would draw the median instead of the mean - if you drop the
                                        # median line from the boxplot
grid(nx = NA, ny = NULL)
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty=1, lwd = 2, xpd = TRUE, ncol = 3,
       cex = 0.8,  bty = "n")
```

The plot above show that the gap filling steps allowed to rescue quite a number
of NAs and allowed us to have a more equivalent number of features per sample.
As we assume that every sample should have a similar amount of features detected.

We can also observe that, on average, the signal distribution from the
individual samples is very similar.

Another way to evaluate the distribution of value within our data are relative log
abundance plots (RLA). Within group RLA assess the tightness of replicate within
groups and should have a median close to zero and low variation around it.
When used across groups, they allow to compare behavior between groups. Below we
will perform the former to show relative abundance of each sample to the other
sample of the same group by setting `group = res$phenotype`.

```{r rla-plot raw and filled1, fig.cap = "RLA plot for the raw data and filled data. Note: outliers are not drawn."}
par(mfrow = c(1, 1), mar = c(0.2, 4.5, 2.5, 3))
boxplot(rowRla(assay(res, "raw_filled"), group = res$phenotype),
        cex = 0.5, pch = 16,
        col = col_sample, ylab = "RLA",
        border = paste0(col_sample, 40), notch = TRUE, boxwex = 1,
        outline = FALSE, xaxt = "n", main = "Filled in data", cex.main = 1)
grid(nx = NA, ny = NULL)
abline(h = 0, lty=3, lwd = 1, col = "black")
legend("topright", col = col_phenotype,
       legend = names(col_phenotype), lty=1, lwd = 2, xpd = TRUE, ncol = 3,
       cex = 0.8,  bty = "n")
```

On the RLA plot above, we can observe that the medians for most samples are
indeed centered around 0. Exception is one of the *CVD* samples. But
normalization (hopefully) helps there.

### Internal standard

We want to select the internal standard compounds for which we have features
defined. For this, we first reuse the internal standards data from before.
Using the `matchValues` function from the `MataboAnnotation` packages, we will
identify features matching m/z and RT of internal standards. With `mzColname`
and `rtColname` we specify the column names in query (our IS) and target
(features detected in the data set) that contain the m/z or RT values.

We then filter these *matches* to only keep IS that match with ONLY one feature
and remove the others.

```{r include=TRUE}
#' Creating a column within our IS table
intern_standard$feature_id <- NA_character_

#' Identify features matching m/z and RT of internal standards.
fdef <- featureDefinitions(data)
fdef$feature_id <- rownames(fdef)
match_intern_standard <- matchValues(
    query = intern_standard,
    target = fdef,
    mzColname = c("mz", "mzmed"),
    rtColname = c("RT", "rtmed"),
    param = MzRtParam(ppm = 50, toleranceRt = 10))

#' Keep only matches with a 1:1 mapping standard to feature.
rem_dups <- function(x) {
    if (nrow(matches(x)) > 1)
        filterMatches(x, index = integer())
    else x
}

match_intern_standard <- MetaboAnnotation::endoapply(match_intern_standard,
                                                     FUN = rem_dups)
intern_standard$feature_id <- match_intern_standard$target_feature_id
intern_standard <- intern_standard[!is.na(intern_standard$feature_id), ]

## Let's look at our internal standards
is_features <- featureChromatograms(
    data, features = intern_standard[c("methionine_13C_15N", "cystine_13C_15N"),
                                     "feature_id"], expandRt = 5)

par(mfrow = c(1, 2))
plot(is_features[1, ], col = col_sample,
     peakBg = paste0(col_sample[chromPeaks(is_features[1, ])[, "sample"]], 40),
     main = intern_standard["methionine_13C_15N", "name"])
abline(v = intern_standard["methionine_13C_15N", "RT"], lty = 2)
plot(is_features[2, ], col = col_sample,
     peakBg = paste0(col_sample[chromPeaks(is_features[2, ])[, "sample"]], 40),
     main = intern_standard["cystine_13C_15N", "name"])
abline(v = intern_standard["cystine_13C_15N", "RT"], lty = 2)
```

As anticipated, our two internal standards have effectively identified features.
Additionally, internal standards play a crucial role in guiding the
normalization process. Given the assumption that the samples were
artificially spiked, we possess a known ground truth—that the abundance or
intensity of the internal standard should be consistent. Consequently,
normalization aims to minimize variation between samples for the internal
standard, reinforcing the reliability of our analyses.

## Between sample normalisation

We will implement between-sample normalization using filled-in features. This
process effectively mitigates variations influenced by technical issues, such
as differences in sample preparation and injection methods.  In this instance,
we will employ a commonly used technique known as median scaling.

### Median scaling

Compute the median for each sample, followed by determining the median of these
individual sample medians. This ensures consistent median values for each sample
throughout the entire data set. Maintaining uniformity in the average total
metabolite abundance across all samples is crucial for effective implementation.

This process aims to establish a shared baseline for the central tendency of
metabolite abundance, mitigating the impact of sample-specific technical
variations. This approach fosters a more robust and comparable analysis of the
top features across the data set. The assumption is that normalizing based on
the median, known for its lower sensitivity to extreme values, enhances the
comparability of top features and ensures a consistent average abundance across
samples.

```{r}
#' Compute median and generate normalization factor
mdns <- apply(assay(res, "raw_filled"), MARGIN = 2,
              median, na.rm = TRUE )
nf_mdn <- mdns / median(mdns)

#' divide dataset by median of median and create a new assay.
assays(res)$norm <- sweep(assay(res, "raw_filled"), MARGIN = 2, nf_mdn,
                                   '/')
```

## Assessing overall effectiveness of the normalization approach

### PCA

```{r fig.width=7, include=TRUE}
#' Full data before
vals <- assay(res, "raw_filled_imputed") |>
    t() |>
    log2() |>
    scale(center = TRUE, scale = TRUE)
pca_res <- prcomp(vals, scale = FALSE, center = FALSE)
pca_int <- prcomp(vals[, intern_standard$feature_id],
                  scale = FALSE, center = FALSE)

#' Full data after
vals <- apply(assay(res, "norm"), MARGIN = 1, na.unidis) |>
    log2() |>
    scale(center = TRUE, scale = TRUE)
pca_res_norm <- prcomp(vals, scale = FALSE, center = FALSE)
pca_int_norm <- prcomp(vals[, intern_standard$feature_id],
                       scale = FALSE, center = FALSE)

par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
plot_pca(pca_res, pc_x = 1, pc_y = 2, pch = 21,
         col = col_sample, bg = paste0(col_sample, 80))
legend("topleft", col = col_phenotype, legend = names(col_phenotype), lty=1, lwd = 2,
       xpd = TRUE, ncol = 3, cex = 0.7, title = "Phenotype", title.cex = 0.8,
       bty = "n")
title(main = "Full data set PCA before norm", cex = 0.5)
plot_pca(pca_res_norm, pc_x = 1, pc_y = 2, pch = 21,
         col = col_sample, bg = paste0(col_sample, 80))
title(main = "Full data set PCA after norm", cex = 0.5)
```

... nothing changed basically; meaning also that data was already OK before
normalization.


### RLA

```{r rla-plot after norm2, include = TRUE, fig.cap = "RLA plot before and after normalization. Note: outliers are not drawn.", fig.height= 7, fig.width=5.5}
par(mfrow = c(2, 1), mar = c(1, 4, 3, 1))

boxplot(rowRla(assay(res, "raw_filled"), group = res$phenotype),
        cex = 0.5, pch = 16, col = col_sample, ylab = "RLA",
        border = paste0(col_sample, 40), notch = TRUE, cex.main = 1,
        outline = FALSE, xaxt = "n", main = "Raw data", boxwex = 1)
grid(nx = NA, ny = NULL)
legend("topleft", inset = c(0, -0.2), col = col_phenotype,
       legend = names(col_phenotype), lty=1, lwd = 2, xpd = TRUE,
       ncol = 3, cex = 0.7, bty = "n")
abline(h = 0, lty=3, lwd = 1, col = "black")

boxplot(rowRla(assay(res, "norm"), group = res$phenotype),
        cex = 0.5, pch = 16,
        col = col_sample, ylab = "RLA",
        border = paste0(col_sample, 40), notch = TRUE, boxwex = 1,
        outline = FALSE, xaxt = "n", main = "After normalization", cex.main = 1)
grid(nx = NA, ny = NULL)
abline(h = 0, lty=3, lwd = 1, col = "black")
```

...Looks much better...

### Internal standards

Below we can see the coefficient of variation as well as the mean and standard
deviation of our IS between the different samples. they are compared between
before and after normalization of our datasets.

```{r internal-standard-table2, include=TRUE, results = "asis"}
#' table of internal standards with mean and sd of abundances (in log2 scale)
tmp_fv <- assay(res, "raw_filled")[intern_standard$feature_id, ]
tmp_fv_norm <- assay(res, "norm")[intern_standard$feature_id, ]
intern_standard$mean_abd <- rowMeans(log2(tmp_fv), na.rm = TRUE)
intern_standard$mean_abd_norm <- rowMeans(log2(tmp_fv_norm), na.rm = TRUE)
intern_standard$sd_abd <- rowSds(log2(tmp_fv), na.rm = TRUE)
intern_standard$sd_abd_norm <- rowSds(log2(tmp_fv_norm), na.rm = TRUE)
intern_standard$CV_raw <- rowRsd(tmp_fv, na.rm = TRUE)
intern_standard$CV_norm <- rowRsd(tmp_fv_norm, na.rm = TRUE)

cpt <- paste("Internal standards with detected and assigned features, mean and",
             "standard deviation of (log2) abundance and Coefficient of",
             "variation before and after normalization.")
pandoc.table(intern_standard[,
             c("mean_abd", "mean_abd_norm", "sd_abd", "sd_abd_norm", "CV_raw",
               "CV_norm")],
             style = "rmarkdown", caption = cpt)
```

...describe results... (they all increase..but could also say they stay
relatively the same)
jo: would say they stay the same. no big changes.

### Sample groups

```{r include=TRUE, results = "asis"}
index_study <- res$phenotype %in% c("CTR", "CVD")
index_QC <- res$phenotype == "QC"

sample_res <- cbind(
    QC_Raw = rowRsd(assay(res, "raw_filled")[, index_QC], na.rm = TRUE),
    QC_norm = rowRsd(assay(res, "norm")[, index_QC], na.rm = TRUE),
    Study_Raw = rowRsd(assay(res, "raw_filled")[, index_study],
                       na.rm = TRUE),
    Study_norm = rowRsd(assay(res, "norm")[, index_study], na.rm = TRUE)
)

#' Quantile
res_df <- data.frame(
    QC_raw = quantile(sample_res[, "QC_Raw"], na.rm = TRUE),
    QC_Norm = quantile(sample_res[, "QC_norm"], na.rm = TRUE),
    Study_raw = quantile(sample_res[, "Study_Raw"], na.rm = TRUE),
    Study_Norm = quantile(sample_res[, "Study_norm"], na.rm = TRUE)
    )
cpt <- paste0("Distribution of CV values across samples for the raw and ",
              "normalized data.")
pandoc.table(res_df, style = "rmarkdown", caption = cpt)
```

```{r}
library(vioplot)
vioplot(sample_res)
grid()
```

plotting does not really bring a lot.
...describe results...

- as expected CV of QCs (technical variance) is lower than for study
  (technical + biological variance) samples
- minimal reduction of CVs by normalization
- no between sample difference present in raw data: no sample preparation or
  processing bias, all samples measured in the same run, thus no differences due
  to biases from MS instrumentation.


Not sure which table to keep.
jo: would keep the first table. 75% quantile is 0.31 anyway, thus 75% of data
have a CV < 31%.

### Conclusion

No much difference but still the RLA plot showed that it allowed to centered the
data around the median...  for bigger and more complex datatset...


# Identification of interesting features

- Pre-filtering.
- Differential abundance analysis.
    r Biocpkg("limma") or other packages


# Annotation

- Different levels of annotation.
- Just m/z (mass).
- m/z and retention time.
- MS/MS spectra + public repository.
- MS/MS spectra + retention time.

# Summary

# Session information

# References

# Additional informations 

```{r}
plot(eics_is_noprocess)

#' Notes on the EICs:
#' - Alanine 13C 15N: signal very low, maybe other ion?
#' - Arginine: very nice signal, RT a bit off.
#' - Aspartic acid: very nice signal.
#' - Carnitine: nothing there, maybe other ion?
#' - Creatinine: nothing there, maybe other ion?
#' - Cystine: very nice signal.
#' - Glucose: nice signal.
#' - Glutamic acid: very nice signal.
#' - Glycine: signal low but ~ OK.
#' - cystine: very nice signal, RT a bit off.
#' - Isoleucine: multiple peaks, most likely both leucine and isoleucine.
#' - Leucine: same as Isoleucine.
#' - Methionine: nice signal, but some other peaks close by.
#' - Phenylalanine: nice signal, but some other peaks close by.
#' - Proline: signal low but ~ OK (maybe other ion?)
#' - Serine: nice signal.
#' - Threonine: nice signal.
#' - Tyrosine: signal low but ~ OK.
#' - Valine: signal OK. Other peaks close by.
#' 

plot(eics_is_chrompeaks) # show chrompeak detection 
plot(eics_is_refined) # show refinement effect
plot(eic_is) # show alignment effect
# no need for really anything else ? 

```


